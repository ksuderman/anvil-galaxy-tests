<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="Results (powered by Planemo)"
           tests="80"
           errors="10"
           failures="7"
           skip="0">
    
    <testcase classname="anndata_import (Test #1)" name="0" time="52.753562450408936">
        
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_loom(    '/galaxy/server/database/objects/3/8/7/dataset_387216cc-54ea-4d52-a1f0-51af7c36ce1d.dat',    sparse=True,    cleanup=False,    X_name='spliced',    obs_names='CellID',    var_names='Gene')adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            Observation names are not unique. To make them unique, call `.obs_names_make_unique`.... storing 'cell_type' as categorical
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #1)" name="0" time="35.404276847839355">
        
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_loom(    '/galaxy/server/database/objects/9/a/e/dataset_9ae6a6c5-9c07-4009-b0da-bbd1087dc6f8.dat',    sparse=True,    cleanup=False,    X_name='spliced',    obs_names='CellID',    var_names='Gene')adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            Observation names are not unique. To make them unique, call `.obs_names_make_unique`.... storing 'cell_type' as categorical
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #2)" name="1" time="35.27673697471619">
        
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_csv(    '/galaxy/server/database/objects/a/4/4/dataset_a44f266f-a0f9-45b0-8d76-ae83e1e08091.dat',    delimiter=',',    first_column_names=True)adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #2)" name="1" time="36.262611389160156">
        
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_csv(    '/galaxy/server/database/objects/4/0/4/dataset_40481f4c-bfe1-49ef-a8ba-e8a73ef05bd3.dat',    delimiter=',',    first_column_names=True)adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #3)" name="2" time="26.689610719680786">
        
            
                <error type="error" message="Tool exit code: None"><![CDATA[
                    { "inputs": {  "hd5_format|in|adata_format": "tabular",  "hd5_format|in|first_column_names": true,  "hd5_format|in|input": {   "id": "e12a618f33fa28de",   "src": "hda"  } }, "job": {  "command_line": "cat \u0027/galaxy/server/database/jobs_directory/000/99/configs/tmp0foa3jxc\u0027 \u0026\u0026 python \u0027/galaxy/server/database/jobs_directory/000/99/configs/tmp0foa3jxc\u0027",  "command_version": null,  "copied_from_job_id": null,  "create_time": "2024-08-29T18:56:24.978664",  "dependencies": [],  "exit_code": null,  "external_id": "gxy-v26dq",  "galaxy_version": "24.1",  "handler": null,  "history_id": "8be07f855fe1b5b9",  "id": "406b2fc1b72efa32",  "inputs": {   "hd5_format|in|input": {    "id": "e12a618f33fa28de",    "src": "hda",    "uuid": "57bfeb13-842c-47fd-83c3-9fa0774e5b1e"   }  },  "job_messages": null,  "job_metrics": [],  "job_runner_name": null,  "job_stderr": null,  "job_stdout": null,  "model_class": "Job",  "output_collections": {},  "outputs": {   "anndata": {    "id": "98ccc325a4e036ba",    "src": "hda",    "uuid": "4e7f3923-b696-4749-813e-00a974144718"   }  },  "params": {   "__input_ext": "\"input\"",   "chromInfo": "\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"",   "dbkey": "\"?\"",   "hd5_format": "{\"__current_case__\": 0, \"filetype\": \"anndata\", \"in\": {\"__current_case__\": 1, \"adata_format\": \"tabular\", \"first_column_names\": true, \"input\": {\"values\": [{\"id\": 136, \"src\": \"hda\"}]}}}"  },  "state": "error",  "stderr": "",  "stdout": "\n\nimport anndata as ad\n    \n    \nadata = ad.read_csv(\n    \u0027/galaxy/server/database/objects/5/7/b/dataset_57bfeb13-842c-47fd-83c3-9fa0774e5b1e.dat\u0027,\n    delimiter=\u0027\\t\u0027,\n    first_column_names=True)\n\nadata.write(\u0027anndata.h5ad\u0027)\n",  "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/anndata_import/anndata_import/0.7.5+galaxy1",  "tool_stderr": "",  "tool_stdout": "\n\nimport anndata as ad\n    \n    \nadata = ad.read_csv(\n    \u0027/galaxy/server/database/objects/5/7/b/dataset_57bfeb13-842c-47fd-83c3-9fa0774e5b1e.dat\u0027,\n    delimiter=\u0027\\t\u0027,\n    first_column_names=True)\n\nadata.write(\u0027anndata.h5ad\u0027)\n",  "update_time": "2024-08-29T18:56:31.624874",  "user_email": "tests@fake.org" }, "output_problems": [  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/anndata_import/anndata_import/0.7.5+galaxy1, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/anndata_import/anndata_import/0.7.5+galaxy1, exit_code: None, stderr: ." ], "status": "failure", "test_index": 2, "time_seconds": 26.689610719680786, "tool_id": "anndata_import", "tool_version": "0.7.5+galaxy1"}
                ]]></error>
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_csv(    '/galaxy/server/database/objects/5/7/b/dataset_57bfeb13-842c-47fd-83c3-9fa0774e5b1e.dat',    delimiter='\t',    first_column_names=True)adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #3)" name="2" time="37.572725772857666">
        
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_csv(    '/galaxy/server/database/objects/c/d/f/dataset_cdf5d8d7-a0a7-45a2-ac06-73fe2f007a3a.dat',    delimiter='\t',    first_column_names=True)adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #4)" name="3" time="34.52470350265503">
        
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_mtx(filename='/galaxy/server/database/objects/a/4/0/dataset_a4031e9b-cef7-46c1-861e-5131581975c0.dat')adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #4)" name="3" time="27.302783012390137">
        
            
                <error type="error" message="Tool exit code: None"><![CDATA[
                    { "inputs": {  "hd5_format|in|adata_format": "mtx",  "hd5_format|in|matrix": {   "id": "07a3d4e7deae70dd",   "src": "hda"  },  "hd5_format|in|tenx|use": "no" }, "job": {  "command_line": "mkdir mtx \u0026\u0026   cat \u0027/galaxy/server/database/jobs_directory/000/118/configs/tmpd7lnpt4k\u0027 \u0026\u0026 python \u0027/galaxy/server/database/jobs_directory/000/118/configs/tmpd7lnpt4k\u0027    \u0026\u0026 rm -rf mtx",  "command_version": null,  "copied_from_job_id": null,  "create_time": "2024-08-29T19:01:13.355946",  "dependencies": [],  "exit_code": null,  "external_id": "gxy-jzn5t",  "galaxy_version": "24.1",  "handler": null,  "history_id": "8be07f855fe1b5b9",  "id": "317a9a6e13d92ad7",  "inputs": {   "hd5_format|in|matrix": {    "id": "07a3d4e7deae70dd",    "src": "hda",    "uuid": "d77ade6b-35f3-45c9-ad46-1e7ee0c46d62"   }  },  "job_messages": null,  "job_metrics": [],  "job_runner_name": null,  "job_stderr": null,  "job_stdout": null,  "model_class": "Job",  "output_collections": {},  "outputs": {   "anndata": {    "id": "b1bb59649c49a128",    "src": "hda",    "uuid": "4ffee9b8-9dc1-45ce-af1c-ee18d3119598"   }  },  "params": {   "__input_ext": "\"input\"",   "chromInfo": "\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"",   "dbkey": "\"?\"",   "hd5_format": "{\"__current_case__\": 0, \"filetype\": \"anndata\", \"in\": {\"__current_case__\": 3, \"adata_format\": \"mtx\", \"matrix\": {\"values\": [{\"id\": 155, \"src\": \"hda\"}]}, \"tenx\": {\"__current_case__\": 0, \"use\": \"no\"}}}"  },  "state": "error",  "stderr": "",  "stdout": "\n\nimport anndata as ad\n    \n    \nadata = ad.read_mtx(filename=\u0027/galaxy/server/database/objects/d/7/7/dataset_d77ade6b-35f3-45c9-ad46-1e7ee0c46d62.dat\u0027)\n\nadata.write(\u0027anndata.h5ad\u0027)\n",  "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/anndata_import/anndata_import/0.7.5+galaxy1",  "tool_stderr": "",  "tool_stdout": "\n\nimport anndata as ad\n    \n    \nadata = ad.read_mtx(filename=\u0027/galaxy/server/database/objects/d/7/7/dataset_d77ade6b-35f3-45c9-ad46-1e7ee0c46d62.dat\u0027)\n\nadata.write(\u0027anndata.h5ad\u0027)\n",  "update_time": "2024-08-29T19:01:20.329990",  "user_email": "tests@fake.org" }, "output_problems": [  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/anndata_import/anndata_import/0.7.5+galaxy1, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/anndata_import/anndata_import/0.7.5+galaxy1, exit_code: None, stderr: ." ], "status": "failure", "test_index": 3, "time_seconds": 27.302783012390137, "tool_id": "anndata_import", "tool_version": "0.7.5+galaxy1"}
                ]]></error>
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_mtx(filename='/galaxy/server/database/objects/d/7/7/dataset_d77ade6b-35f3-45c9-ad46-1e7ee0c46d62.dat')adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #5)" name="4" time="34.86219048500061">
        
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_umi_tools('umi_tools_input.gz')adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #5)" name="4" time="33.40431356430054">
        
            
            <system-out><![CDATA[
            import anndata as ad        adata = ad.read_umi_tools('umi_tools_input.gz')adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #6)" name="5" time="43.80562114715576">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #6)" name="5" time="46.35754418373108">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #7)" name="6" time="37.439547300338745">
        
            
            <system-out><![CDATA[
            import anndata as ad        import scanpy as scadata = sc.read_10x_h5('/galaxy/server/database/objects/8/2/0/dataset_820ff168-f4a6-4164-bfa7-8f2e2d3a8016.dat')adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="anndata_import (Test #7)" name="6" time="38.03124642372131">
        
            
            <system-out><![CDATA[
            import anndata as ad        import scanpy as scadata = sc.read_10x_h5('/galaxy/server/database/objects/e/c/a/dataset_eca16a8b-f90f-4a9e-8a8b-8d7c6701abc7.dat')adata.write('anndata.h5ad')
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="bcftools_plugin_fixploidy (Test #1)" name="0" time="24.697795867919922">
        
            <error type="error" message="Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: ."><![CDATA[
                { "execution_problem": "Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: .", "status": "error", "test_index": 0, "time_seconds": 24.697795867919922, "tool_id": "bcftools_plugin_fixploidy", "tool_version": "1.10"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="bcftools_stats (Test #1)" name="0" time="58.45500636100769">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="bcftools_stats (Test #2)" name="1" time="">
        
            <error type="error" message=""><![CDATA[
                { "status": "skip", "test_index": 1, "tool_id": "bcftools_stats", "tool_version": "1.10"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="bcftools_stats (Test #3)" name="2" time="36.140700578689575">
        
            
                <error type="error" message="Tool exit code: 1"><![CDATA[
                    { "inputs": {  "input_file": {   "id": "ccd98f1ea27eddcf",   "src": "hda"  },  "plot_title": "Plot for mpileup.vcf" }, "job": {  "command_line": "export BCFTOOLS_PLUGINS=`which bcftools | sed \u0027s,bin/bcftools,libexec/bcftools,\u0027`;     bgzip -c \u0027/galaxy/server/database/objects/e/a/9/dataset_ea968d84-42d5-4bf6-9035-4d6843ce7143.dat\u0027 \u003e input0.vcf.gz \u0026\u0026 bcftools index input0.vcf.gz \u0026\u0026 echo \u0027input0.vcf.gz\u0027 \u003e\u003e vcfs_list \u0026\u0026                     bcftools stats                              input0.vcf.gz  \u003e \u0027/galaxy/server/database/objects/a/b/2/dataset_ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda.dat\u0027 \u0026\u0026 plot-vcfstats -p \u0027plot_tmp/\u0027 -T \u0027Plot for mpileup.vcf\u0027 -s \u0027/galaxy/server/database/objects/a/b/2/dataset_ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda.dat\u0027 || (printf \"The content of plot_tmp/plot-vcfstats.log is:\\n\" \u003e\u00262 \u0026\u0026 cat plot_tmp/plot-vcfstats.log \u003e\u00262 \u0026\u0026 exit 1)",  "command_version": "Version: 1.10.2 (using htslib 1.10.2)",  "copied_from_job_id": null,  "create_time": "2024-08-29T19:18:17.765272",  "dependencies": [],  "exit_code": 1,  "external_id": "gxy-9bbzg",  "galaxy_version": "24.1",  "handler": null,  "history_id": "8be07f855fe1b5b9",  "id": "fafedd146a46aeb4",  "inputs": {   "input_file": {    "id": "ccd98f1ea27eddcf",    "src": "hda",    "uuid": "ea968d84-42d5-4bf6-9035-4d6843ce7143"   }  },  "job_messages": [   {    "code_desc": "",    "desc": "Fatal error: Exit code 1 ()",    "error_level": 3,    "exit_code": 1,    "type": "exit_code"   },   {    "code_desc": "",    "desc": "Fatal error: ",    "error_level": 3,    "match": "error:",    "stream": "stderr",    "type": "regex"   }  ],  "job_metrics": [   {    "name": "runtime_seconds",    "plugin": "core",    "raw_value": "2.0000000",    "title": "Job Runtime (Wall Clock)",    "value": "2 seconds"   },   {    "name": "end_epoch",    "plugin": "core",    "raw_value": "1724959101.0000000",    "title": "Job End Time",    "value": "2024-08-29 19:18:21"   },   {    "name": "start_epoch",    "plugin": "core",    "raw_value": "1724959099.0000000",    "title": "Job Start Time",    "value": "2024-08-29 19:18:19"   },   {    "name": "galaxy_memory_mb",    "plugin": "core",    "raw_value": "4080.0000000",    "title": "Memory Allocated (MB)",    "value": "4080"   },   {    "name": "galaxy_slots",    "plugin": "core",    "raw_value": "1.0000000",    "title": "Cores Allocated",    "value": "1"   }  ],  "job_runner_name": null,  "job_stderr": "",  "job_stdout": "",  "model_class": "Job",  "output_collections": {},  "outputs": {   "output_file": {    "id": "23810b061d541123",    "src": "hda",    "uuid": "ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda"   },   "output_pdf": {    "id": "dae8472b548a0917",    "src": "hda",    "uuid": "5f21b3ec-4d5d-4e4a-bf1b-3caf0d91de2f"   }  },  "params": {   "__input_ext": "\"input\"",   "chromInfo": "\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"",   "dbkey": "\"?\"",   "inputB_file": null,   "plot_title": "\"Plot for mpileup.vcf\"",   "sec_default": "{\"af_tag\": \"\", \"afbins\": {\"__current_case__\": 0, \"afbins_select\": \"default\"}, \"depth\": {\"__current_case__\": 0, \"set_depth\": \"no\"}, \"exons_file\": null, \"first_allele_only\": false, \"reference_source\": {\"__current_case__\": 0, \"reference_source_selector\": \"\"}, \"split_by_ID\": false, \"user_tstv\": \"\", \"verbose\": false}",   "sec_restrict": "{\"apply_filters\": \"\", \"collapse\": null, \"exclude\": null, \"include\": null, \"invert_samples\": false, \"invert_samples_file\": false, \"regions\": {\"__current_case__\": 0, \"regions_src\": \"__none__\"}, \"samples\": \"\", \"samples_file\": null, \"targets\": {\"__current_case__\": 0, \"targets_src\": \"__none__\"}}"  },  "state": "error",  "stderr": "Parsing bcftools stats output: /galaxy/server/database/objects/a/b/2/dataset_ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda.dat\nPlotting graphs: python3 plot.py\nCreating PDF: tectonic summary.tex \u003eplot-vcfstats.log 2\u003e\u00261\nThe command exited with non-zero status, please consult the output of tectonic: plot_tmp/plot-vcfstats.log\n\n at /usr/local/bin/plot-vcfstats line 111.\n\tmain::error(\"The command exited with non-zero status, please consult the o\"...) called at /usr/local/bin/plot-vcfstats line 2086\n\tmain::create_pdf(HASH(0x58ce7a253c78)) called at /usr/local/bin/plot-vcfstats line 72\nThe content of plot_tmp/plot-vcfstats.log is:\nnote: this is a BETA release; ask questions and report bugs at https://tectonic.newton.cx/\nnote: indexing https://archive.org/services/purl/net/pkgwpub/tectonic-default\nerror: could not get backend summary digest\ncaused by: couldn\u0027t probe https://archive.org/services/purl/net/pkgwpub/tectonic-default\ncaused by: Invalid Status provided\n",  "stdout": "",  "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.10",  "tool_stderr": "Parsing bcftools stats output: /galaxy/server/database/objects/a/b/2/dataset_ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda.dat\nPlotting graphs: python3 plot.py\nCreating PDF: tectonic summary.tex \u003eplot-vcfstats.log 2\u003e\u00261\nThe command exited with non-zero status, please consult the output of tectonic: plot_tmp/plot-vcfstats.log\n\n at /usr/local/bin/plot-vcfstats line 111.\n\tmain::error(\"The command exited with non-zero status, please consult the o\"...) called at /usr/local/bin/plot-vcfstats line 2086\n\tmain::create_pdf(HASH(0x58ce7a253c78)) called at /usr/local/bin/plot-vcfstats line 72\nThe content of plot_tmp/plot-vcfstats.log is:\nnote: this is a BETA release; ask questions and report bugs at https://tectonic.newton.cx/\nnote: indexing https://archive.org/services/purl/net/pkgwpub/tectonic-default\nerror: could not get backend summary digest\ncaused by: couldn\u0027t probe https://archive.org/services/purl/net/pkgwpub/tectonic-default\ncaused by: Invalid Status provided\n",  "tool_stdout": "",  "update_time": "2024-08-29T19:18:32.867225",  "user_email": "tests@fake.org" }, "output_problems": [  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.10, exit_code: 1, stderr: Parsing bcftools stats output: /galaxy/server/database/objects/a/b/2/dataset_ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda.dat\nPlotting graphs: python3 plot.py\nCreating PDF: tectonic summary.tex \u003eplot-vcfstats.log 2\u003e\u00261\nThe command exited with non-zero status, please consult the output of tectonic: plot_tmp/plot-vcfstats.log\n\n at /usr/local/bin/plot-vcfstats line 111.\n\tmain::error(\"The command exited with non-zero status, please consult the o\"...) called at /usr/local/bin/plot-vcfstats line 2086\n\tmain::create_pdf(HASH(0x58ce7a253c78)) called at /usr/local/bin/plot-vcfstats line 72\nThe content of plot_tmp/plot-vcfstats.log is:\nnote: this is a BETA release; ask questions and report bugs at https://tectonic.newton.cx/\nnote: indexing https://archive.org/services/purl/net/pkgwpub/tectonic-default\nerror: could not get backend summary digest\ncaused by: couldn\u0027t probe https://archive.org/services/purl/net/pkgwpub/tectonic-default\ncaused by: Invalid Status provided\n.",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.10, exit_code: 1, stderr: Parsing bcftools stats output: /galaxy/server/database/objects/a/b/2/dataset_ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda.dat\nPlotting graphs: python3 plot.py\nCreating PDF: tectonic summary.tex \u003eplot-vcfstats.log 2\u003e\u00261\nThe command exited with non-zero status, please consult the output of tectonic: plot_tmp/plot-vcfstats.log\n\n at /usr/local/bin/plot-vcfstats line 111.\n\tmain::error(\"The command exited with non-zero status, please consult the o\"...) called at /usr/local/bin/plot-vcfstats line 2086\n\tmain::create_pdf(HASH(0x58ce7a253c78)) called at /usr/local/bin/plot-vcfstats line 72\nThe content of plot_tmp/plot-vcfstats.log is:\nnote: this is a BETA release; ask questions and report bugs at https://tectonic.newton.cx/\nnote: indexing https://archive.org/services/purl/net/pkgwpub/tectonic-default\nerror: could not get backend summary digest\ncaused by: couldn\u0027t probe https://archive.org/services/purl/net/pkgwpub/tectonic-default\ncaused by: Invalid Status provided\n.",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.10, exit_code: 1, stderr: Parsing bcftools stats output: /galaxy/server/database/objects/a/b/2/dataset_ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda.dat\nPlotting graphs: python3 plot.py\nCreating PDF: tectonic summary.tex \u003eplot-vcfstats.log 2\u003e\u00261\nThe command exited with non-zero status, please consult the output of tectonic: plot_tmp/plot-vcfstats.log\n\n at /usr/local/bin/plot-vcfstats line 111.\n\tmain::error(\"The command exited with non-zero status, please consult the o\"...) called at /usr/local/bin/plot-vcfstats line 2086\n\tmain::create_pdf(HASH(0x58ce7a253c78)) called at /usr/local/bin/plot-vcfstats line 72\nThe content of plot_tmp/plot-vcfstats.log is:\nnote: this is a BETA release; ask questions and report bugs at https://tectonic.newton.cx/\nnote: indexing https://archive.org/services/purl/net/pkgwpub/tectonic-default\nerror: could not get backend summary digest\ncaused by: couldn\u0027t probe https://archive.org/services/purl/net/pkgwpub/tectonic-default\ncaused by: Invalid Status provided\n." ], "status": "failure", "test_index": 2, "time_seconds": 36.140700578689575, "tool_id": "bcftools_stats", "tool_version": "1.10"}
                ]]></error>
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            Parsing bcftools stats output: /galaxy/server/database/objects/a/b/2/dataset_ab2e7c45-7e30-4bbd-b23c-bd7ec5e2cfda.datPlotting graphs: python3 plot.pyCreating PDF: tectonic summary.tex >plot-vcfstats.log 2>&1The command exited with non-zero status, please consult the output of tectonic: plot_tmp/plot-vcfstats.log at /usr/local/bin/plot-vcfstats line 111.main::error("The command exited with non-zero status, please consult the o"...) called at /usr/local/bin/plot-vcfstats line 2086main::create_pdf(HASH(0x58ce7a253c78)) called at /usr/local/bin/plot-vcfstats line 72The content of plot_tmp/plot-vcfstats.log is:note: this is a BETA release; ask questions and report bugs at https://tectonic.newton.cx/note: indexing https://archive.org/services/purl/net/pkgwpub/tectonic-defaulterror: could not get backend summary digestcaused by: couldn't probe https://archive.org/services/purl/net/pkgwpub/tectonic-defaultcaused by: Invalid Status provided
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="collection_element_identifiers (Test #1)" name="0" time="55.042094707489014">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="collection_element_identifiers (Test #2)" name="1" time="34.41624140739441">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="deeptools_plot_correlation (Test #1)" name="0" time="81.4540376663208">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="deeptools_plot_correlation (Test #2)" name="1" time="25.691678047180176">
        
            
                <error type="error" message="Tool exit code: None"><![CDATA[
                    { "inputs": {  "corData": {   "id": "1d967b36682f67e9",   "src": "hda"  },  "outFileFormat": "png",  "plotting_type|plotTitle": "Test Plot",  "plotting_type|whatToPlot": "scatterplot",  "removeOutliers": true }, "job": {  "command_line": "plotCorrelation --corData \u0027/galaxy/server/database/objects/e/a/7/dataset_ea7dcf71-95ba-463e-b62e-06f5385156e4.dat\u0027 --plotFile \u0027/galaxy/server/database/objects/4/8/5/dataset_485c63e8-2510-4eb1-bb41-30288b08fdbe.dat\u0027 --corMethod \u0027spearman\u0027 --whatToPlot \u0027scatterplot\u0027 --plotTitle \u0027Test Plot\u0027   --plotFileFormat \u0027png\u0027 --removeOutliers",  "command_version": null,  "copied_from_job_id": null,  "create_time": "2024-08-29T18:35:44.697451",  "dependencies": [],  "exit_code": null,  "external_id": "gxy-qxvc8",  "galaxy_version": "24.1",  "handler": null,  "history_id": "8be07f855fe1b5b9",  "id": "1d967b36682f67e9",  "inputs": {   "corData": {    "id": "1d967b36682f67e9",    "src": "hda",    "uuid": "ea7dcf71-95ba-463e-b62e-06f5385156e4"   }  },  "job_messages": null,  "job_metrics": [],  "job_runner_name": null,  "job_stderr": null,  "job_stdout": null,  "model_class": "Job",  "output_collections": {},  "outputs": {   "outFileName": {    "id": "097ec29e6fd920c6",    "src": "hda",    "uuid": "485c63e8-2510-4eb1-bb41-30288b08fdbe"   }  },  "params": {   "__input_ext": "\"input\"",   "chromInfo": "\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"",   "corMethod": "\"spearman\"",   "dbkey": "\"?\"",   "outFileCorMatrix": "false",   "outFileFormat": "\"png\"",   "plotting_type": "{\"__current_case__\": 1, \"log1p\": false, \"plotTitle\": \"Test Plot\", \"whatToPlot\": \"scatterplot\", \"xrange_conditional\": {\"__current_case__\": 1, \"xrange_select\": \"no\"}, \"yrange_conditional\": {\"__current_case__\": 1, \"yrange_select\": \"no\"}}",   "removeOutliers": "true",   "skipZeros": "false"  },  "state": "error",  "stderr": "",  "stdout": "",  "tool_id": "toolshed.g2.bx.psu.edu/repos/bgruening/deeptools_plot_correlation/deeptools_plot_correlation/3.3.2.0.0",  "tool_stderr": "",  "tool_stdout": "",  "update_time": "2024-08-29T18:35:50.776125",  "user_email": "tests@fake.org" }, "output_problems": [  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/bgruening/deeptools_plot_correlation/deeptools_plot_correlation/3.3.2.0.0, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/bgruening/deeptools_plot_correlation/deeptools_plot_correlation/3.3.2.0.0, exit_code: None, stderr: ." ], "status": "failure", "test_index": 1, "time_seconds": 25.691678047180176, "tool_id": "deeptools_plot_correlation", "tool_version": "3.3.2.0.0"}
                ]]></error>
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="flash (Test #1)" name="0" time="39.90640997886658">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="flash (Test #2)" name="1" time="11.720888614654541">
        
            <error type="error" message="Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: ."><![CDATA[
                { "execution_problem": "Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: .", "status": "error", "test_index": 1, "time_seconds": 11.720888614654541, "tool_id": "flash", "tool_version": "1.2.11.4"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="flash (Test #3)" name="2" time="37.86620759963989">
        
            
            <system-out><![CDATA[
            [FLASH] Starting FLASH v1.2.11[FLASH] Fast Length Adjustment of SHort reads[FLASH]  [FLASH] Input files:[FLASH]     /galaxy/server/database/objects/5/9/7/dataset_59750b8b-4f63-4117-a8c5-f8384a2dc687.dat[FLASH]     /galaxy/server/database/objects/9/7/1/dataset_971dfc2c-f755-4c33-8e26-01c09dc52d9a.dat[FLASH]  [FLASH] Output files:[FLASH]     ./out.extendedFrags.fastq[FLASH]     ./out.notCombined_1.fastq[FLASH]     ./out.notCombined_2.fastq[FLASH]     ./out.hist[FLASH]     ./out.histogram[FLASH]  [FLASH] Parameters:[FLASH]     Min overlap:           10[FLASH]     Max overlap:           65[FLASH]     Max mismatch density:  0.250000[FLASH]     Allow "outie" pairs:   false[FLASH]     Cap mismatch quals:    false[FLASH]     Combiner threads:      1[FLASH]     Input format:          FASTQ, phred_offset=64[FLASH]     Output format:         FASTQ, phred_offset=64[FLASH]  [FLASH] Starting reader and writer threads[FLASH] Starting 1 combiner threads[FLASH] Processed 200 read pairs[FLASH]  [FLASH] Read combination statistics:[FLASH]     Total pairs:      200[FLASH]     Combined pairs:   5[FLASH]     Uncombined pairs: 195[FLASH]     Percent combined: 2.50%[FLASH]  [FLASH] Writing histogram files.[FLASH]  [FLASH] FLASH v1.2.11 complete![FLASH] 0.025 seconds elapsed
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="flash (Test #4)" name="3" time="37.177271127700806">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="flash (Test #5)" name="4" time="27.341303825378418">
        
            
                <error type="error" message="Tool exit code: None"><![CDATA[
                    { "inputs": {  "generate_histogram": false,  "layout|reads": {   "id": "76b437d30ddce0a6",   "src": "hdca"  },  "layout|select_layout": "collection" }, "job": {  "command_line": "flash --threads=${GALAXY_SLOTS:-1} -m 10 -M 65 -x 0.25  \u0027/galaxy/server/database/objects/b/8/d/dataset_b8d09d84-2ae8-4b12-900e-3c35ab6bf1ca.dat\u0027 \u0027/galaxy/server/database/objects/7/d/d/dataset_7dd43e6f-b0a1-4b43-a42c-3e904cb1277e.dat\u0027 -p 33 -z --output-suffix=\u0027\u0027",  "command_version": null,  "copied_from_job_id": null,  "create_time": "2024-08-29T18:38:19.796546",  "dependencies": [],  "exit_code": null,  "external_id": "gxy-vt8pw",  "galaxy_version": "24.1",  "handler": null,  "history_id": "8be07f855fe1b5b9",  "id": "f43557430632eca9",  "inputs": {   "layout|reads1": {    "id": "952cc307249de22d",    "src": "hda",    "uuid": "b8d09d84-2ae8-4b12-900e-3c35ab6bf1ca"   },   "layout|reads2": {    "id": "a3395fb8e5fd9b64",    "src": "hda",    "uuid": "7dd43e6f-b0a1-4b43-a42c-3e904cb1277e"   }  },  "job_messages": null,  "job_metrics": [],  "job_runner_name": null,  "job_stderr": null,  "job_stdout": null,  "model_class": "Job",  "output_collections": {},  "outputs": {   "hist": {    "id": "5808b1dd833c1db6",    "src": "hda",    "uuid": "1eda1d31-df92-47be-96ab-77ffb403bb4c"   },   "log": {    "id": "3a79d8cd53ffb289",    "src": "hda",    "uuid": "8a4f390b-74a8-4283-8d28-edd5fa9784ae"   },   "merged_reads": {    "id": "65405b5c40bf2c86",    "src": "hda",    "uuid": "5b87b1e0-455b-4dd8-b0ef-b8b23685419b"   },   "unmerged_reads_f": {    "id": "8096b4884f4160ef",    "src": "hda",    "uuid": "08e8ae8c-7cc0-4541-a43c-b00d168da133"   },   "unmerged_reads_r": {    "id": "411df93f248e3833",    "src": "hda",    "uuid": "45bc38dd-cfca-4a7e-ae31-f3d828fb49e4"   }  },  "params": {   "__input_ext": "\"fastqsanger.gz\"",   "allow_outies": "false",   "chromInfo": "\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"",   "dbkey": "\"?\"",   "generate_histogram": "false",   "layout": "{\"__current_case__\": 1, \"reads\": {\"values\": [{\"id\": 4, \"src\": \"hdca\"}]}, \"select_layout\": \"collection\"}",   "max_mismatch_density": "\"0.25\"",   "max_overlap": "\"65\"",   "min_overlap": "\"10\"",   "save_log": "false"  },  "state": "error",  "stderr": "",  "stdout": "[FLASH] Starting FLASH v1.2.11\n[FLASH] Fast Length Adjustment of SHort reads\n[FLASH]  \n[FLASH] Input files:\n[FLASH]     /galaxy/server/database/objects/b/8/d/dataset_b8d09d84-2ae8-4b12-900e-3c35ab6bf1ca.dat\n[FLASH]     /galaxy/server/database/objects/7/d/d/dataset_7dd43e6f-b0a1-4b43-a42c-3e904cb1277e.dat\n[FLASH]  \n[FLASH] Output files:\n[FLASH]     ./out.extendedFrags.fastq\n[FLASH]     ./out.notCombined_1.fastq\n[FLASH]     ./out.notCombined_2.fastq\n[FLASH]     ./out.hist\n[FLASH]     ./out.histogram\n[FLASH]  \n[FLASH] Parameters:\n[FLASH]     Min overlap:           10\n[FLASH]     Max overlap:           65\n[FLASH]     Max mismatch density:  0.250000\n[FLASH]     Allow \"outie\" pairs:   false\n[FLASH]     Cap mismatch quals:    false\n[FLASH]     Combiner threads:      1\n[FLASH]     Input format:          FASTQ, phred_offset=33\n[FLASH]     Output format:         FASTQ, phred_offset=33, gzip\n[FLASH]  \n[FLASH] Starting reader and writer threads\n[FLASH] Starting 1 combiner threads\n[FLASH] Processed 500 read pairs\n[FLASH]  \n[FLASH] Read combination statistics:\n[FLASH]     Total pairs:      500\n[FLASH]     Combined pairs:   18\n[FLASH]     Uncombined pairs: 482\n[FLASH]     Percent combined: 3.60%\n[FLASH]  \n[FLASH] Writing histogram files.\n[FLASH]  \n[FLASH] FLASH v1.2.11 complete!\n[FLASH] 0.044 seconds elapsed\n",  "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/flash/flash/1.2.11.4",  "tool_stderr": "",  "tool_stdout": "[FLASH] Starting FLASH v1.2.11\n[FLASH] Fast Length Adjustment of SHort reads\n[FLASH]  \n[FLASH] Input files:\n[FLASH]     /galaxy/server/database/objects/b/8/d/dataset_b8d09d84-2ae8-4b12-900e-3c35ab6bf1ca.dat\n[FLASH]     /galaxy/server/database/objects/7/d/d/dataset_7dd43e6f-b0a1-4b43-a42c-3e904cb1277e.dat\n[FLASH]  \n[FLASH] Output files:\n[FLASH]     ./out.extendedFrags.fastq\n[FLASH]     ./out.notCombined_1.fastq\n[FLASH]     ./out.notCombined_2.fastq\n[FLASH]     ./out.hist\n[FLASH]     ./out.histogram\n[FLASH]  \n[FLASH] Parameters:\n[FLASH]     Min overlap:           10\n[FLASH]     Max overlap:           65\n[FLASH]     Max mismatch density:  0.250000\n[FLASH]     Allow \"outie\" pairs:   false\n[FLASH]     Cap mismatch quals:    false\n[FLASH]     Combiner threads:      1\n[FLASH]     Input format:          FASTQ, phred_offset=33\n[FLASH]     Output format:         FASTQ, phred_offset=33, gzip\n[FLASH]  \n[FLASH] Starting reader and writer threads\n[FLASH] Starting 1 combiner threads\n[FLASH] Processed 500 read pairs\n[FLASH]  \n[FLASH] Read combination statistics:\n[FLASH]     Total pairs:      500\n[FLASH]     Combined pairs:   18\n[FLASH]     Uncombined pairs: 482\n[FLASH]     Percent combined: 3.60%\n[FLASH]  \n[FLASH] Writing histogram files.\n[FLASH]  \n[FLASH] FLASH v1.2.11 complete!\n[FLASH] 0.044 seconds elapsed\n",  "update_time": "2024-08-29T18:38:25.487520",  "user_email": "tests@fake.org" }, "output_problems": [  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/flash/flash/1.2.11.4, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/flash/flash/1.2.11.4, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/flash/flash/1.2.11.4, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/flash/flash/1.2.11.4, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/flash/flash/1.2.11.4, exit_code: None, stderr: ." ], "status": "failure", "test_index": 4, "time_seconds": 27.341303825378418, "tool_id": "flash", "tool_version": "1.2.11.4"}
                ]]></error>
            
            <system-out><![CDATA[
            [FLASH] Starting FLASH v1.2.11[FLASH] Fast Length Adjustment of SHort reads[FLASH]  [FLASH] Input files:[FLASH]     /galaxy/server/database/objects/b/8/d/dataset_b8d09d84-2ae8-4b12-900e-3c35ab6bf1ca.dat[FLASH]     /galaxy/server/database/objects/7/d/d/dataset_7dd43e6f-b0a1-4b43-a42c-3e904cb1277e.dat[FLASH]  [FLASH] Output files:[FLASH]     ./out.extendedFrags.fastq[FLASH]     ./out.notCombined_1.fastq[FLASH]     ./out.notCombined_2.fastq[FLASH]     ./out.hist[FLASH]     ./out.histogram[FLASH]  [FLASH] Parameters:[FLASH]     Min overlap:           10[FLASH]     Max overlap:           65[FLASH]     Max mismatch density:  0.250000[FLASH]     Allow "outie" pairs:   false[FLASH]     Cap mismatch quals:    false[FLASH]     Combiner threads:      1[FLASH]     Input format:          FASTQ, phred_offset=33[FLASH]     Output format:         FASTQ, phred_offset=33, gzip[FLASH]  [FLASH] Starting reader and writer threads[FLASH] Starting 1 combiner threads[FLASH] Processed 500 read pairs[FLASH]  [FLASH] Read combination statistics:[FLASH]     Total pairs:      500[FLASH]     Combined pairs:   18[FLASH]     Uncombined pairs: 482[FLASH]     Percent combined: 3.60%[FLASH]  [FLASH] Writing histogram files.[FLASH]  [FLASH] FLASH v1.2.11 complete![FLASH] 0.044 seconds elapsed
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="lofreq_call (Test #1)" name="0" time="46.6494836807251">
        
            
            <system-out><![CDATA[
            INFO [2024-08-29 19:14:08,069]: Using 2 threads with following basic args: lofreq call --verbose --ref reference.fa --sig 0.01 --bonf dynamic reads.bamINFO [2024-08-29 19:14:08,083]: Adding 5 commands to mp-poolNumber of substitution tests performed: 66Number of indel tests performed: 0INFO [2024-08-29 19:14:09,546]: Executing lofreq filter -i /galaxy/server/database/jobs_directory/000/157/tmp/lofreq2_call_parallelloscusxu/concat.vcf.gz -o variants.vcf --snvqual-thresh 38 --indelqual-thresh 20set_lofreq_standard
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="lofreq_call (Test #2)" name="1" time="13.207357406616211">
        
            <error type="error" message="Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: ."><![CDATA[
                { "execution_problem": "Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: .", "status": "error", "test_index": 1, "time_seconds": 13.207357406616211, "tool_id": "lofreq_call", "tool_version": "2.1.5+galaxy2"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="lofreq_call (Test #3)" name="2" time="36.482340574264526">
        
            
                <error type="error" message="Tool exit code: None"><![CDATA[
                    { "inputs": {  "call_control|set_call_options": "yes",  "call_control|source_qual|use_src_qual|def_nm_q": "40",  "call_control|source_qual|use_src_qual|ign_vcf": {   "id": "2002ed0f4a7a8962",   "src": "hda"  },  "call_control|source_qual|use_src_qual|src_qual": "--src-qual",  "reads": {   "id": "70f19232469852ac",   "src": "hda"  },  "reference_source|ref": {   "id": "990d71fd9c2b3c28",   "src": "hda"  },  "reference_source|ref_selector": "history" }, "job": {  "command_line": "ln -s \u0027/galaxy/server/database/objects/4/1/7/dataset_41761218-84b6-481d-9b6a-ad8df78102c0.dat\u0027 reference.fa \u0026\u0026 lofreq faidx reference.fa 2\u003e\u00261 || echo \"Error running samtools faidx for indexing fasta reference for lofreq\" \u003e\u00262 \u0026\u0026  ln -s \u0027/galaxy/server/database/objects/4/3/6/dataset_436e4297-e2c7-4776-9415-06cb181b20ae.dat\u0027 reads.bam \u0026\u0026 ln -s -f \u0027/galaxy/server/database/objects/_metadata_files/8/3/0/metadata_830e6fc5-eab7-4f48-9ea5-dfaa102d6472.dat\u0027 reads.bam.bai \u0026\u0026 ln -s \u0027/galaxy/server/database/objects/3/8/2/dataset_382442c5-f47e-4ffe-8abc-0d1a35935e36.dat\u0027 ign0.vcf \u0026\u0026   lofreq call-parallel --pp-threads ${GALAXY_SLOTS:-1} --verbose  --ref \u0027reference.fa\u0027 --out variants.vcf   --min-cov 1 --max-depth 1000000  --min-bq 6 --min-alt-bq 6    --min-mq 0 --max-mq 255 --src-qual --ign-vcf \u0027ign0.vcf\u0027 --def-nm-q 40 --min-jq 0 --min-alt-jq 0 --def-alt-jq 0  --sig 0.01 --bonf dynamic   reads.bam 2\u003e\u00261  || (tool_exit_code=$? \u0026\u0026 cat \"$TMPDIR/lofreq2_call_parallel*/*.log\" 1\u003e\u00262 \u0026\u0026 exit $tool_exit_code)  \u0026\u0026 echo set_lofreq_standard",  "command_version": null,  "copied_from_job_id": null,  "create_time": "2024-08-29T19:15:05.882584",  "dependencies": [],  "exit_code": null,  "external_id": "gxy-ck4q9",  "galaxy_version": "24.1",  "handler": null,  "history_id": "8be07f855fe1b5b9",  "id": "745405cc613233f5",  "inputs": {   "call_control|source_qual|use_src_qual|ign_vcf": {    "id": "2002ed0f4a7a8962",    "src": "hda",    "uuid": "382442c5-f47e-4ffe-8abc-0d1a35935e36"   },   "call_control|source_qual|use_src_qual|ign_vcf1": {    "id": "2002ed0f4a7a8962",    "src": "hda",    "uuid": "382442c5-f47e-4ffe-8abc-0d1a35935e36"   },   "reads": {    "id": "70f19232469852ac",    "src": "hda",    "uuid": "436e4297-e2c7-4776-9415-06cb181b20ae"   },   "reference_source|ref": {    "id": "990d71fd9c2b3c28",    "src": "hda",    "uuid": "41761218-84b6-481d-9b6a-ad8df78102c0"   }  },  "job_messages": null,  "job_metrics": [],  "job_runner_name": null,  "job_stderr": null,  "job_stdout": null,  "model_class": "Job",  "output_collections": {},  "outputs": {   "variants": {    "id": "08546619c4e1fceb",    "src": "hda",    "uuid": "d63e14e6-2d59-4d39-9fad-1f6f17880ceb"   }  },  "params": {   "__input_ext": "\"input\"",   "call_control": "{\"__current_case__\": 1, \"align_quals\": {\"alnqual\": {\"__current_case__\": 0, \"alnqual_choice\": {\"__current_case__\": 1, \"alnquals_to_use\": \"\", \"extended_baq\": true}, \"use_alnqual\": \"\"}}, \"bc_quals\": {\"alt_bq\": {\"__current_case__\": 0, \"modify\": \"\"}, \"min_alt_bq\": \"6\", \"min_bq\": \"6\"}, \"coverage\": {\"max_depth\": \"1000000\", \"min_cov\": \"1\"}, \"joint_qual\": {\"def_alt_jq\": \"0\", \"min_alt_jq\": \"0\", \"min_jq\": \"0\"}, \"map_quals\": {\"min_mq\": \"0\", \"use_mq\": {\"__current_case__\": 0, \"max_mq\": \"255\", \"no_mq\": \"\"}}, \"pe\": {\"use_orphan\": false}, \"set_call_options\": \"yes\", \"source_qual\": {\"use_src_qual\": {\"__current_case__\": 1, \"def_nm_q\": \"40\", \"ign_vcf\": {\"values\": [{\"id\": 216, \"src\": \"hda\"}]}, \"src_qual\": \"--src-qual\"}}}",   "chromInfo": "\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"",   "dbkey": "\"?\"",   "filter_control": "{\"__current_case__\": 2, \"bonf\": \"dynamic\", \"filter_type\": \"set_lofreq_standard\", \"others\": \"\", \"sig\": \"0.01\"}",   "reference_source": "{\"__current_case__\": 1, \"ref\": {\"values\": [{\"id\": 215, \"src\": \"hda\"}]}, \"ref_selector\": \"history\"}",   "regions": "{\"__current_case__\": 0, \"restrict_to_region\": \"genome\"}",   "variant_types": "\"\""  },  "state": "error",  "stderr": "",  "stdout": "INFO [2024-08-29 19:15:08,430]: Using 2 threads with following basic args: lofreq call --verbose --ref reference.fa --min-cov 1 --max-depth 1000000 --min-bq 6 --min-alt-bq 6 --min-mq 0 --max-mq 255 --src-qual --ign-vcf ign0.vcf --def-nm-q 40 --min-jq 0 --min-alt-jq 0 --def-alt-jq 0 --sig 0.01 --bonf dynamic reads.bam\n\nINFO [2024-08-29 19:15:08,444]: Adding 5 commands to mp-pool\nNumber of substitution tests performed: 66\nNumber of indel tests performed: 0\nINFO [2024-08-29 19:15:10,082]: Executing lofreq filter -i /galaxy/server/database/jobs_directory/000/163/tmp/lofreq2_call_parallel879cm1wq/concat.vcf.gz -o variants.vcf --snvqual-thresh 38 --indelqual-thresh 20\n\nset_lofreq_standard\n",  "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/lofreq_call/lofreq_call/2.1.5+galaxy2",  "tool_stderr": "",  "tool_stdout": "INFO [2024-08-29 19:15:08,430]: Using 2 threads with following basic args: lofreq call --verbose --ref reference.fa --min-cov 1 --max-depth 1000000 --min-bq 6 --min-alt-bq 6 --min-mq 0 --max-mq 255 --src-qual --ign-vcf ign0.vcf --def-nm-q 40 --min-jq 0 --min-alt-jq 0 --def-alt-jq 0 --sig 0.01 --bonf dynamic reads.bam\n\nINFO [2024-08-29 19:15:08,444]: Adding 5 commands to mp-pool\nNumber of substitution tests performed: 66\nNumber of indel tests performed: 0\nINFO [2024-08-29 19:15:10,082]: Executing lofreq filter -i /galaxy/server/database/jobs_directory/000/163/tmp/lofreq2_call_parallel879cm1wq/concat.vcf.gz -o variants.vcf --snvqual-thresh 38 --indelqual-thresh 20\n\nset_lofreq_standard\n",  "update_time": "2024-08-29T19:15:13.631125",  "user_email": "tests@fake.org" }, "output_problems": [  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/lofreq_call/lofreq_call/2.1.5+galaxy2, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/lofreq_call/lofreq_call/2.1.5+galaxy2, exit_code: None, stderr: ." ], "status": "failure", "test_index": 2, "time_seconds": 36.482340574264526, "tool_id": "lofreq_call", "tool_version": "2.1.5+galaxy2"}
                ]]></error>
            
            <system-out><![CDATA[
            INFO [2024-08-29 19:15:08,430]: Using 2 threads with following basic args: lofreq call --verbose --ref reference.fa --min-cov 1 --max-depth 1000000 --min-bq 6 --min-alt-bq 6 --min-mq 0 --max-mq 255 --src-qual --ign-vcf ign0.vcf --def-nm-q 40 --min-jq 0 --min-alt-jq 0 --def-alt-jq 0 --sig 0.01 --bonf dynamic reads.bamINFO [2024-08-29 19:15:08,444]: Adding 5 commands to mp-poolNumber of substitution tests performed: 66Number of indel tests performed: 0INFO [2024-08-29 19:15:10,082]: Executing lofreq filter -i /galaxy/server/database/jobs_directory/000/163/tmp/lofreq2_call_parallel879cm1wq/concat.vcf.gz -o variants.vcf --snvqual-thresh 38 --indelqual-thresh 20set_lofreq_standard
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="lofreq_call (Test #4)" name="3" time="38.60809350013733">
        
            
            <system-out><![CDATA[
            INFO [2024-08-29 19:15:38,138]: Using 2 threads with following basic args: lofreq call --verbose --ref reference.fa --sig 1 --bonf 1 --no-default-filter reads.bamINFO [2024-08-29 19:15:38,151]: Adding 5 commands to mp-poolNumber of substitution tests performed: 66Number of indel tests performed: 0INFO [2024-08-29 19:15:39,405]: Copying concatenated vcf file to final destinationset_all_off
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="lofreq_call (Test #5)" name="4" time="39.058610677719116">
        
            
                <error type="error" message="Tool exit code: None"><![CDATA[
                    { "inputs": {  "filter_control|filter_type": "set_all_off",  "reads": {   "id": "788a1c0b569d15ff",   "src": "hda"  },  "reference_source|ref": {   "id": "a90da8c21fa5930e",   "src": "hda"  },  "reference_source|ref_selector": "history",  "variant_types": "--call-indels --only-indels" }, "job": {  "command_line": "ln -s \u0027/galaxy/server/database/objects/9/0/0/dataset_90093f1e-02eb-4b4c-9c05-1717ae21dc0a.dat\u0027 reference.fa \u0026\u0026 lofreq faidx reference.fa 2\u003e\u00261 || echo \"Error running samtools faidx for indexing fasta reference for lofreq\" \u003e\u00262 \u0026\u0026  ln -s \u0027/galaxy/server/database/objects/a/e/6/dataset_ae6a17c3-f908-45a1-a0c2-3631fd033757.dat\u0027 reads.bam \u0026\u0026 ln -s -f \u0027/galaxy/server/database/objects/_metadata_files/c/a/6/metadata_ca6f7b07-e17c-423a-aa1b-9d8c8ca385a5.dat\u0027 reads.bam.bai \u0026\u0026   lofreq call-parallel --pp-threads ${GALAXY_SLOTS:-1} --verbose  --ref \u0027reference.fa\u0027 --out variants.vcf --call-indels --only-indels    --sig 1 --bonf 1 --no-default-filter  reads.bam 2\u003e\u00261  || (tool_exit_code=$? \u0026\u0026 cat \"$TMPDIR/lofreq2_call_parallel*/*.log\" 1\u003e\u00262 \u0026\u0026 exit $tool_exit_code)  \u0026\u0026 ln -s variants.vcf variants.vcf.gz \u0026\u0026 gzip -df variants.vcf.gz \u0026\u0026 echo set_all_off",  "command_version": null,  "copied_from_job_id": null,  "create_time": "2024-08-29T19:16:16.792475",  "dependencies": [],  "exit_code": null,  "external_id": "gxy-lxpb5",  "galaxy_version": "24.1",  "handler": null,  "history_id": "8be07f855fe1b5b9",  "id": "4ff89bc9805a94d8",  "inputs": {   "reads": {    "id": "788a1c0b569d15ff",    "src": "hda",    "uuid": "ae6a17c3-f908-45a1-a0c2-3631fd033757"   },   "reference_source|ref": {    "id": "a90da8c21fa5930e",    "src": "hda",    "uuid": "90093f1e-02eb-4b4c-9c05-1717ae21dc0a"   }  },  "job_messages": null,  "job_metrics": [],  "job_runner_name": null,  "job_stderr": null,  "job_stdout": null,  "model_class": "Job",  "output_collections": {},  "outputs": {   "variants": {    "id": "1a351017415be727",    "src": "hda",    "uuid": "0f673f80-9837-4b3e-ba5b-54cf1727ce00"   }  },  "params": {   "__input_ext": "\"input\"",   "call_control": "{\"__current_case__\": 0, \"set_call_options\": \"no\"}",   "chromInfo": "\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"",   "dbkey": "\"?\"",   "filter_control": "{\"__current_case__\": 0, \"bonf\": \"1\", \"filter_type\": \"set_all_off\", \"others\": \"--no-default-filter\", \"sig\": \"1\"}",   "reference_source": "{\"__current_case__\": 1, \"ref\": {\"values\": [{\"id\": 222, \"src\": \"hda\"}]}, \"ref_selector\": \"history\"}",   "regions": "{\"__current_case__\": 0, \"restrict_to_region\": \"genome\"}",   "variant_types": "\"--call-indels --only-indels\""  },  "state": "error",  "stderr": "",  "stdout": "INFO [2024-08-29 19:16:18,732]: Using 2 threads with following basic args: lofreq call --verbose --ref reference.fa --call-indels --only-indels --sig 1 --bonf 1 --no-default-filter reads.bam\n\nINFO [2024-08-29 19:16:18,745]: Adding 5 commands to mp-pool\nNumber of substitution tests performed: 0\nNumber of indel tests performed: 9\nINFO [2024-08-29 19:16:27,527]: Copying concatenated vcf file to final destination\nset_all_off\n",  "tool_id": "toolshed.g2.bx.psu.edu/repos/iuc/lofreq_call/lofreq_call/2.1.5+galaxy2",  "tool_stderr": "",  "tool_stdout": "INFO [2024-08-29 19:16:18,732]: Using 2 threads with following basic args: lofreq call --verbose --ref reference.fa --call-indels --only-indels --sig 1 --bonf 1 --no-default-filter reads.bam\n\nINFO [2024-08-29 19:16:18,745]: Adding 5 commands to mp-pool\nNumber of substitution tests performed: 0\nNumber of indel tests performed: 9\nINFO [2024-08-29 19:16:27,527]: Copying concatenated vcf file to final destination\nset_all_off\n",  "update_time": "2024-08-29T19:16:31.479396",  "user_email": "tests@fake.org" }, "output_problems": [  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/lofreq_call/lofreq_call/2.1.5+galaxy2, exit_code: None, stderr: .",  "Job in error state.. tool_id: toolshed.g2.bx.psu.edu/repos/iuc/lofreq_call/lofreq_call/2.1.5+galaxy2, exit_code: None, stderr: ." ], "status": "failure", "test_index": 4, "time_seconds": 39.058610677719116, "tool_id": "lofreq_call", "tool_version": "2.1.5+galaxy2"}
                ]]></error>
            
            <system-out><![CDATA[
            INFO [2024-08-29 19:16:18,732]: Using 2 threads with following basic args: lofreq call --verbose --ref reference.fa --call-indels --only-indels --sig 1 --bonf 1 --no-default-filter reads.bamINFO [2024-08-29 19:16:18,745]: Adding 5 commands to mp-poolNumber of substitution tests performed: 0Number of indel tests performed: 9INFO [2024-08-29 19:16:27,527]: Copying concatenated vcf file to final destinationset_all_off
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="medaka_variant (Test #1)" name="0" time="64.8663227558136">
        
            
            <system-out><![CDATA[
            [18:41:09 - DataIndex] Loaded 1/2 (50.00%) sample files.[18:41:09 - DataIndex] Loaded 2/2 (100.00%) sample files.[18:41:09 - Variants] Label decoding is:0: ('*',)1: ('A',)2: ('C',)3: ('G',)4: ('T',)[18:41:09 - Variants] Processing NC_045512.2:0-.[18:41:09 - TrimOverlap] NC_045512.2:30.0-2939.0 is contained within NC_045512.2:30.0-2939.0, skipping.
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="medaka_variant (Test #2)" name="1" time="42.830238819122314">
        
            
            <system-out><![CDATA[
            [18:41:59 - DataIndex] Loaded 1/1 (100.00%) sample files.[18:41:59 - Variants] Label decoding is:0: ('*',)1: ('A',)2: ('C',)3: ('G',)4: ('T',)[18:41:59 - Variants] Processing NC_045512.2:0-.
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="medaka_variant (Test #3)" name="2" time="36.075745820999146">
        
            
            <system-out><![CDATA[
            [18:42:38 - DataIndex] Loaded 1/1 (100.00%) sample files.[18:42:38 - Variants] Label decoding is:0: ('*',)1: ('A',)2: ('C',)3: ('G',)4: ('T',)[18:42:38 - Variants] Processing NC_045512.2:0-.
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="poretools_times (Test #1)" name="0" time="56.060402154922485">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="poretools_times (Test #2)" name="1" time="11.00738787651062">
        
            <error type="error" message="Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: ."><![CDATA[
                { "execution_problem": "Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: .", "status": "error", "test_index": 1, "time_seconds": 11.00738787651062, "tool_id": "poretools_times", "tool_version": "0.6.1a1.0"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="poretools_times (Test #3)" name="2" time="34.32418656349182">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="poretools_times (Test #4)" name="3" time="33.21528220176697">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="poretools_times (Test #5)" name="4" time="34.07245373725891">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #1)" name="0" time="59.93066382408142">
        
            
            <system-out><![CDATA[
            null device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #1)" name="0" time="40.186529874801636">
        
            
            <system-out><![CDATA[
            null device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #2)" name="1" time="37.17351412773132">
        
            
            <system-out><![CDATA[
            NULLNULLNULLNULLNULLNULLNULLNULLNULLNULLNULLNULLnull device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #2)" name="1" time="46.58012366294861">
        
            
            <system-out><![CDATA[
            NULLNULLNULLNULLNULLNULLNULLNULLNULLNULLNULLNULLnull device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #3)" name="2" time="39.68501543998718">
        
            
            <system-out><![CDATA[
            [1] 1NULL[1] 1NULL[1] 1NULL[1] 1NULLnull device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #3)" name="2" time="46.45799922943115">
        
            
            <system-out><![CDATA[
            [1] 1NULL[1] 1NULL[1] 1NULL[1] 1NULLnull device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #4)" name="3" time="37.111289262771606">
        
            
            <system-out><![CDATA[
            [1] 1NULL[1] 1NULL[1] 1NULL[1] 1NULLNULLNULLNULLnull device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #4)" name="3" time="47.799038887023926">
        
            
            <system-out><![CDATA[
            [1] 1NULL[1] 1NULL[1] 1NULL[1] 1NULLNULLNULLNULLnull device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #5)" name="4" time="45.751007318496704">
        
            
            <system-out><![CDATA[
            NULLNULLNULLNULLNULLNULLNULLNULLNULLNULLNULLNULL[1] 1NULL[1] 1NULL[1] 1NULL[1] 1NULLNULLNULLNULLnull device           1 
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="raceid_inspecttrajectory (Test #5)" name="4" time="15.63772177696228">
        
            <error type="error" message="Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: ."><![CDATA[
                { "execution_problem": "Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: .", "status": "error", "test_index": 4, "time_seconds": 15.63772177696228, "tool_id": "raceid_inspecttrajectory", "tool_version": "0.2.3+galaxy2"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="sailfish (Test #1)" name="0" time="11.316082239151001">
        
            <error type="error" message="Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: ."><![CDATA[
                { "execution_problem": "Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: .", "status": "error", "test_index": 0, "time_seconds": 11.316082239151001, "tool_id": "sailfish", "tool_version": "0.10.1.1"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="sailfish (Test #2)" name="1" time="51.752681016922">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            Version Info: This is the most recent version of Sailfishwriting log to ./index_dir/logs/sailfish_index.logRapMap Indexer[Step 1 of 4] : counting k-mersElapsed time: 0.00087059sReplaced 0 non-ATCG nucleotidesClipped poly-A tails from 0 transcriptsBuilding rank-select dictionary and saving to disk doneElapsed time: 6.0809e-05sWriting sequence data to file . . . doneElapsed time: 8.384e-05s[info] Building 32-bit suffix array (length of generalized text is 28577)Building suffix array . . . successsaving to disk . . . doneElapsed time: 0.00014482sdoneElapsed time: 0.00288273sprocessed 0 positionskhash had 18955 keyssaving hash to disk . . . doneElapsed time: 0.00143861sVersion Info: This is the most recent version of Sailfish# sailfish (quasi-mapping-based) v0.9.2# [ program ] => sailfish # [ command ] => quant # [ index ] => { ./index_dir }# [ mates1 ] => { /dev/fd/63 }# [ mates2 ] => { /dev/fd/62 }# [ libType ] => { IU }# [ output ] => { ./results }# [ threads ] => { 6 }# [ gcSizeSamp ] => { 1 }# [ gcSpeedSamp ] => { 1 }# [ fldMean ] => { 200 }# [ fldSD ] => { 80 }# [ maxReadOcc ] => { 200 }# [ maxFragLen ] => { 1000 }# [ txpAggregationKey ] => { gene_id }# [ numBiasSamples ] => { 1000000 }# [ numFragSamples ] => { 10000 }# [ numGibbsSamples ] => { 0 }# [ numBootstraps ] => { 0 }Logs will be written to ./results/logs[2024-08-29 18:46:30.489] [jointLog] [info] parsing read library formatthere is 1 libLoading 32-bit quasi indexIndex contained 15 targetsLoaded targets[2024-08-29 18:46:30.561] [jointLog] [info] Loading Quasi index[2024-08-29 18:46:30.566] [jointLog] [info] done[2024-08-29 18:46:30.585] [jointLog] [info] Gathered fragment lengths from all threads[2024-08-29 18:46:30.585] [jointLog] [warning] Sailfish saw fewer then 10000 uniquely mapped reads so 200 will be used as the mean fragment length and 80 as the standard deviation for effective length correction[2024-08-29 18:46:30.586] [jointLog] [info] Estimating effective lengthsDone Quasi-Mapping [2024-08-29 18:46:30.594] [jointLog] [info] Computed 21 rich equivalence classes for further processing[2024-08-29 18:46:30.594] [jointLog] [info] Counted 10000 total reads in the equivalence classes [2024-08-29 18:46:30.594] [jointLog] [info] Starting optimizer:[2024-08-29 18:46:30.594] [jointLog] [info] Optimizing over 21 equivalence classes[2024-08-29 18:46:30.594] [jointLog] [info] iteration = 0 | max rel diff. = 14.873[2024-08-29 18:46:30.595] [jointLog] [info] iteration = 64 | max rel diff. = 0.00117687[2024-08-29 18:46:30.595] [jointLog] [info] Finished optimizer[2024-08-29 18:46:30.595] [jointLog] [info] writing output [2024-08-29 18:46:30.563] [stderrLog] [info] Loading Suffix Array [2024-08-29 18:46:30.564] [stderrLog] [info] Loading Position Hash[2024-08-29 18:46:30.564] [stderrLog] [info] Loading Transcript Info [2024-08-29 18:46:30.565] [stderrLog] [info] Loading Rank-Select Bit Array[2024-08-29 18:46:30.566] [stderrLog] [info] There were 15 set bits in the bit array[2024-08-29 18:46:30.566] [stderrLog] [info] Computing transcript lengths[2024-08-29 18:46:30.566] [stderrLog] [info] Waiting to finish loading hash[2024-08-29 18:46:30.566] [stderrLog] [info] Done loading index
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="sailfish (Test #3)" name="2" time="40.600252628326416">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            Version Info: This is the most recent version of Sailfishwriting log to ./index_dir/logs/sailfish_index.logRapMap Indexer[Step 1 of 4] : counting k-mersElapsed time: 0.00137278sReplaced 0 non-ATCG nucleotidesClipped poly-A tails from 0 transcriptsBuilding rank-select dictionary and saving to disk doneElapsed time: 3.887e-05sWriting sequence data to file . . . doneElapsed time: 7.039e-05s[info] Building 32-bit suffix array (length of generalized text is 28577)Building suffix array . . . successsaving to disk . . . doneElapsed time: 0.000158179sdoneElapsed time: 0.00274057sprocessed 0 positionskhash had 18955 keyssaving hash to disk . . . doneElapsed time: 0.00159426sVersion Info: This is the most recent version of Sailfish# sailfish (quasi-mapping-based) v0.9.2# [ program ] => sailfish # [ command ] => quant # [ index ] => { ./index_dir }# [ mates1 ] => { ./mate1.fastq }# [ mates2 ] => { ./mate2.fastq }# [ libType ] => { IU }# [ output ] => { ./results }# [ biasCorrect ] => { }# [ threads ] => { 6 }# [ gcSizeSamp ] => { 1 }# [ gcSpeedSamp ] => { 1 }# [ fldMean ] => { 200 }# [ fldSD ] => { 80 }# [ maxReadOcc ] => { 200 }# [ maxFragLen ] => { 1000 }# [ txpAggregationKey ] => { gene_id }# [ numBiasSamples ] => { 1000000 }# [ numFragSamples ] => { 10000 }# [ numGibbsSamples ] => { 0 }# [ numBootstraps ] => { 0 }Logs will be written to ./results/logs[2024-08-29 18:47:12.581] [jointLog] [info] parsing read library formatthere is 1 libLoading 32-bit quasi index[2024-08-29 18:47:12.653] [jointLog] [info] Loading Quasi index[2024-08-29 18:47:12.660] [jointLog] [info] doneIndex contained 15 targetsLoaded targets[2024-08-29 18:47:12.687] [jointLog] [info] Gathered fragment lengths from all threads[2024-08-29 18:47:12.687] [jointLog] [warning] Sailfish saw fewer then 10000 uniquely mapped reads so 200 will be used as the mean fragment length and 80 as the standard deviation for effective length correction[2024-08-29 18:47:12.688] [jointLog] [info] Estimating effective lengthsDone Quasi-Mapping [2024-08-29 18:47:12.698] [jointLog] [info] Computed 21 rich equivalence classes for further processing[2024-08-29 18:47:12.698] [jointLog] [info] Counted 10000 total reads in the equivalence classes [2024-08-29 18:47:12.698] [jointLog] [info] Starting optimizer:[2024-08-29 18:47:12.699] [jointLog] [info] Optimizing over 21 equivalence classes[2024-08-29 18:47:12.699] [jointLog] [info] iteration = 0 | max rel diff. = 14.873[2024-08-29 18:47:12.699] [jointLog] [info] iteration 50, recomputing effective lengths[2024-08-29 18:47:12.701] [jointLog] [info] iteration = 63 | max rel diff. = 0.00199953[2024-08-29 18:47:12.701] [jointLog] [info] Finished optimizer[2024-08-29 18:47:12.701] [jointLog] [info] writing output [2024-08-29 18:47:12.655] [stderrLog] [info] Loading Position Hash[2024-08-29 18:47:12.656] [stderrLog] [info] Loading Suffix Array [2024-08-29 18:47:12.657] [stderrLog] [info] Loading Transcript Info [2024-08-29 18:47:12.659] [stderrLog] [info] Loading Rank-Select Bit Array[2024-08-29 18:47:12.659] [stderrLog] [info] There were 15 set bits in the bit array[2024-08-29 18:47:12.660] [stderrLog] [info] Computing transcript lengths[2024-08-29 18:47:12.660] [stderrLog] [info] Waiting to finish loading hash[2024-08-29 18:47:12.660] [stderrLog] [info] Done loading index
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="sailfish (Test #4)" name="3" time="45.07950139045715">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            Version Info: This is the most recent version of Sailfishwriting log to ./index_dir/logs/sailfish_index.logRapMap Indexer[Step 1 of 4] : counting k-mersElapsed time: 0.00159895sReplaced 0 non-ATCG nucleotidesClipped poly-A tails from 0 transcriptsBuilding rank-select dictionary and saving to disk doneElapsed time: 7.694e-05sWriting sequence data to file . . . doneElapsed time: 9.551e-05s[info] Building 32-bit suffix array (length of generalized text is 28577)Building suffix array . . . successsaving to disk . . . doneElapsed time: 0.00017066sdoneElapsed time: 0.00532326sprocessed 0 positionskhash had 18955 keyssaving hash to disk . . . doneElapsed time: 0.00161546sVersion Info: This is the most recent version of Sailfish# sailfish (quasi-mapping-based) v0.9.2# [ program ] => sailfish # [ command ] => quant # [ index ] => { ./index_dir }# [ mates1 ] => { ./mate1.fastq }# [ mates2 ] => { ./mate2.fastq }# [ libType ] => { IU }# [ output ] => { ./results }# [ biasCorrect ] => { }# [ threads ] => { 6 }# [ gcSizeSamp ] => { 1 }# [ gcSpeedSamp ] => { 1 }# [ fldMean ] => { 200 }# [ fldSD ] => { 80 }# [ maxReadOcc ] => { 200 }# [ geneMap ] => { ./geneMap.tabular }# [ maxFragLen ] => { 1000 }# [ txpAggregationKey ] => { gene_id }# [ numBiasSamples ] => { 1000000 }# [ numFragSamples ] => { 10000 }# [ numGibbsSamples ] => { 0 }# [ numBootstraps ] => { 0 }Logs will be written to ./results/logs[2024-08-29 18:47:58.522] [jointLog] [info] parsing read library formatthere is 1 libLoading 32-bit quasi index[2024-08-29 18:47:58.594] [stderrLog] [info] Loading Suffix Array [2024-08-29 18:47:58.595] [stderrLog] [info] Loading Position Hash[2024-08-29 18:47:58.596] [stderrLog] [info] Loading Transcript Info [2024-08-29 18:47:58.597] [stderrLog] [info] Loading Rank-Select Bit Array[2024-08-29 18:47:58.597] [stderrLog] [info] There were 15 set bits in the bit array[2024-08-29 18:47:58.598] [stderrLog] [info] Computing transcript lengths[2024-08-29 18:47:58.598] [stderrLog] [info] Waiting to finish loading hash[2024-08-29 18:47:58.598] [stderrLog] [info] Done loading indexIndex contained 15 targetsLoaded targets[2024-08-29 18:47:58.592] [jointLog] [info] Loading Quasi index[2024-08-29 18:47:58.598] [jointLog] [info] done[2024-08-29 18:47:58.620] [jointLog] [info] Gathered fragment lengths from all threads[2024-08-29 18:47:58.620] [jointLog] [warning] Sailfish saw fewer then 10000 uniquely mapped reads so 200 will be used as the mean fragment length and 80 as the standard deviation for effective length correction[2024-08-29 18:47:58.621] [jointLog] [info] Estimating effective lengthsDone Quasi-Mapping [2024-08-29 18:47:58.629] [jointLog] [info] Computed 21 rich equivalence classes for further processing[2024-08-29 18:47:58.629] [jointLog] [info] Counted 10000 total reads in the equivalence classes [2024-08-29 18:47:58.630] [jointLog] [info] Starting optimizer:[2024-08-29 18:47:58.630] [jointLog] [info] Optimizing over 21 equivalence classes[2024-08-29 18:47:58.630] [jointLog] [info] iteration = 0 | max rel diff. = 14.873[2024-08-29 18:47:58.630] [jointLog] [info] iteration 50, recomputing effective lengths[2024-08-29 18:47:58.632] [jointLog] [info] iteration = 63 | max rel diff. = 0.00199953[2024-08-29 18:47:58.632] [jointLog] [info] Finished optimizer[2024-08-29 18:47:58.632] [jointLog] [info] writing output Computing gene-level abundance estimatesThere were 3 transcripts mapping to 3 genesWARNING: couldn't find transcript named [NR_031764]; returning transcript  as it's own genedoneAggregating expressions to gene level . . . done
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_mpileup (Test #1)" name="0" time="46.41303992271423">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            [mpileup] 3 samples in 3 input files
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_mpileup (Test #2)" name="1" time="35.49046468734741">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            [mpileup] 1 samples in 1 input files
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_mpileup (Test #3)" name="2" time="34.25970149040222">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            [mpileup] 1 samples in 1 input files
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_mpileup (Test #4)" name="3" time="35.80056977272034">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            [mpileup] 1 samples in 1 input files
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_mpileup (Test #5)" name="4" time="36.3719687461853">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            [mpileup] 1 samples in 1 input files
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_phase (Test #1)" name="0" time="38.14951133728027">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_phase (Test #1)" name="0" time="36.395610332489014">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_phase (Test #2)" name="1" time="12.01382827758789">
        
            <error type="error" message="Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: ."><![CDATA[
                { "execution_problem": "Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: .", "status": "error", "test_index": 1, "time_seconds": 12.01382827758789, "tool_id": "samtools_phase", "tool_version": "2.0.2"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="samtools_phase (Test #2)" name="1" time="35.60111880302429">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_phase (Test #3)" name="2" time="34.23170447349548">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="samtools_phase (Test #3)" name="2" time="37.15361833572388">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="scanpy_normalize (Test #1)" name="0" time="64.88463616371155">
        
            
            <system-out><![CDATA[
            [n_obs  n_vars]-    640  11[obs]-    cell_type-    n_counts[uns]-    cell_type_colors-    highlights-    iroot
            ]]></system-out>
            <system-err><![CDATA[
            Observation names are not unique. To make them unique, call `.obs_names_make_unique`.
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="scanpy_normalize (Test #2)" name="1" time="42.59922552108765">
        
            
            <system-out><![CDATA[
            [n_obs  n_vars]-    1000  998[obs]-    n_counts_all[var]-    n_counts-    mean-    std[uns]-    log1p
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="scanpy_normalize (Test #3)" name="2" time="44.40456295013428">
        
            
            <system-out><![CDATA[
            [n_obs  n_vars]-    100  1592[obs]-    paul15_clusters[uns]-    iroot-    log1p[obsm]-    X_pca
            ]]></system-out>
            <system-err><![CDATA[
            ... storing 'paul15_clusters' as categorical
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="scanpy_normalize (Test #4)" name="3" time="42.24290132522583">
        
            
            <system-out><![CDATA[
            [n_obs  n_vars]-    1000  1[obs]-    n_counts_all-    n_genes[var]-    n_counts-    mean-    std-    n_cells[uns]-    log1p
            ]]></system-out>
            <system-err><![CDATA[
            WARNING: Some cells have total count of genes equal to zero
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="scanpy_scale_data (Test #1)" name="0" time="0.23737025260925293">
        
            <error type="error" message="Input staging problem: Test input file (find_variable_genes.h5) cannot be found."><![CDATA[
                { "execution_problem": "Input staging problem: Test input file (find_variable_genes.h5) cannot be found.", "status": "error", "test_index": 0, "time_seconds": 0.23737025260925293, "tool_id": "scanpy_scale_data", "tool_version": "1.8.1+3+galaxy0"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="scanpy_scale_data (Test #1)" name="0" time="0.2376866340637207">
        
            <error type="error" message="Input staging problem: Test input file (find_variable_genes.h5) cannot be found."><![CDATA[
                { "execution_problem": "Input staging problem: Test input file (find_variable_genes.h5) cannot be found.", "status": "error", "test_index": 0, "time_seconds": 0.2376866340637207, "tool_id": "scanpy_scale_data", "tool_version": "1.8.1+3+galaxy0"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="snpeff_sars_cov_2 (Test #1)" name="0" time="55.363651752471924">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="vcf2tsv (Test #1)" name="0" time="39.845867395401">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="vcf2tsv (Test #2)" name="1" time="36.19113612174988">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="vcfhethom (Test #1)" name="0" time="35.821255683898926">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="vcfhethom (Test #2)" name="1" time="32.21267485618591">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="vcfhethom (Test #3)" name="2" time="34.87114500999451">
        
            
            <system-out><![CDATA[
            
            ]]></system-out>
            <system-err><![CDATA[
            
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="volcanoplot (Test #1)" name="0" time="55.78285622596741">
        
            
            <system-out><![CDATA[
            [1] "Header row detected"null device           1 R version 4.0.5 (2021-03-31)Platform: x86_64-conda-linux-gnu (64-bit)Running under: Debian GNU/Linux 10 (buster)Matrix products: defaultBLAS/LAPACK: /usr/local/lib/libopenblasp-r0.3.15.solocale: [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   attached base packages:[1] stats     graphics  grDevices utils     datasets  methods   base     other attached packages:[1] ggrepel_0.9.1 ggplot2_3.3.3 dplyr_1.0.6  loaded via a namespace (and not attached): [1] Rcpp_1.0.6       magrittr_2.0.1   tidyselect_1.1.1 munsell_0.5.0    [5] colorspace_2.0-1 R6_2.5.0         rlang_0.4.11     fansi_0.5.0      [9] grid_4.0.5       gtable_0.3.0     utf8_1.2.1       withr_2.4.2     [13] ellipsis_0.3.2   digest_0.6.27    tibble_3.1.2     lifecycle_1.0.0 [17] crayon_1.4.1     purrr_0.3.4      farver_2.1.0     vctrs_0.3.8     [21] glue_1.4.2       labeling_0.4.2   compiler_4.0.5   pillar_1.6.1    [25] generics_0.1.0   scales_1.1.1     pkgconfig_2.0.3 
            ]]></system-out>
            <system-err><![CDATA[
            Warning message:In Sys.setlocale("LC_MESSAGES", "en_US.UTF-8") :  OS reports request to set locale to "en_US.UTF-8" cannot be honored
            ]]></system-err>
        
    </testcase>
    
    <testcase classname="volcanoplot (Test #2)" name="1" time="20.09043288230896">
        
            <error type="error" message="Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: ."><![CDATA[
                { "execution_problem": "Input staging problem: Job in error state.. tool_id: upload1, exit_code: None, stderr: .", "status": "error", "test_index": 1, "time_seconds": 20.09043288230896, "tool_id": "volcanoplot", "tool_version": "0.0.5"}
            ]]></error>
        
    </testcase>
    
    <testcase classname="volcanoplot (Test #3)" name="2" time="41.88077473640442">
        
            
            <system-out><![CDATA[
            null device           1 R version 4.0.5 (2021-03-31)Platform: x86_64-conda-linux-gnu (64-bit)Running under: Debian GNU/Linux 10 (buster)Matrix products: defaultBLAS/LAPACK: /usr/local/lib/libopenblasp-r0.3.15.solocale: [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   attached base packages:[1] stats     graphics  grDevices utils     datasets  methods   base     other attached packages:[1] ggrepel_0.9.1 ggplot2_3.3.3 dplyr_1.0.6  loaded via a namespace (and not attached): [1] Rcpp_1.0.6       magrittr_2.0.1   tidyselect_1.1.1 munsell_0.5.0    [5] colorspace_2.0-1 R6_2.5.0         rlang_0.4.11     fansi_0.5.0      [9] grid_4.0.5       gtable_0.3.0     utf8_1.2.1       withr_2.4.2     [13] ellipsis_0.3.2   digest_0.6.27    tibble_3.1.2     lifecycle_1.0.0 [17] crayon_1.4.1     purrr_0.3.4      farver_2.1.0     vctrs_0.3.8     [21] glue_1.4.2       labeling_0.4.2   compiler_4.0.5   pillar_1.6.1    [25] generics_0.1.0   scales_1.1.1     pkgconfig_2.0.3 
            ]]></system-out>
            <system-err><![CDATA[
            Warning message:In Sys.setlocale("LC_MESSAGES", "en_US.UTF-8") :  OS reports request to set locale to "en_US.UTF-8" cannot be honored
            ]]></system-err>
        
    </testcase>
    
</testsuite>